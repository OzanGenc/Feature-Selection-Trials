{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination of MRI Features\n",
    "In this notebook MRI based features of Cerebral Blood Flow(CBF), arterial Blood Volume(aBV), Fractional Anisotropy(FA), Mean Diffusivity(MD), functional MRI(fMRI), spectroscopy are used to predict Parkinson's Disease Mild Cognitive Impairment (PD-MCI).\n",
    "Most informative features are tried to be found as biomarkers indicating PD-MCI status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import sklearn.ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from pandas import ExcelWriter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import collections\n",
    "\n",
    "import re\n",
    "\n",
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Excel Files\n",
    "Files containing each modalities are imported as DataFrames. MR spectroscopic data are imported from four different files including four different metabolite ratio values of Glutamine (Glu), N-acetyl aspartate (Naa), Myo-inositol (Ins) and Choline divided by Creatine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\Users\\DELL003\\Desktop\\PD_Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FA = pd.read_excel('DTI.xlsx', sheet_name = 'FA', index_col='ID')\n",
    "FA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD = pd.read_excel('DTI.xlsx', sheet_name = 'MD', index_col='ID')\n",
    "MD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aBV = pd.read_excel('aBV.xlsx', sheet_name = 'Mean', index_col='ID')\n",
    "aBV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBF = pd.read_excel('CBF.xlsx', sheet_name = 'Mean', index_col='ID')\n",
    "CBF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri = pd.read_excel('fmri.xlsx', sheet_name = 'Sheet1', index_col='ID')\n",
    "fmri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = pd.read_excel('group.xlsx', sheet_name = 'Sheet1', index_col='ID')\n",
    "group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glu = pd.read_excel('spectroscopy.xlsx', sheet_name = 'Glu', index_col='ID')\n",
    "naa = pd.read_excel('spectroscopy.xlsx', sheet_name = 'Naa', index_col='ID')\n",
    "ins = pd.read_excel('spectroscopy.xlsx', sheet_name = 'Ins', index_col='ID')\n",
    "cho = pd.read_excel('spectroscopy.xlsx', sheet_name = 'Cho', index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting only MRI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glu = glu.loc[:, glu.columns.str.contains('7Networks', regex=True)]\n",
    "naa = naa.loc[:, naa.columns.str.contains('7Networks', regex=True)]\n",
    "ins = ins.loc[:, ins.columns.str.contains('7Networks', regex=True)]\n",
    "cho = cho.loc[:, cho.columns.str.contains('7Networks', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding suffixes to each feature types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glu.columns = glu.columns + '_glu'\n",
    "naa.columns = naa.columns + '_naa'\n",
    "ins.columns = ins.columns + '_ins'\n",
    "cho.columns = cho.columns + '_cho'\n",
    "CBF.columns = pd.Series([str(col) for col in CBF.columns]) + '_CBF'\n",
    "aBV.columns = pd.Series([str(col) for col in aBV.columns]) + '_aBV'\n",
    "FA.columns = FA.columns + '_FA'\n",
    "MD.columns = MD.columns + '_MD'\n",
    "fmri.columns = fmri.columns + '_fmri'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equaling index names in order to merge the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glu_index = pd.Series(glu.index)\n",
    "naa_index = pd.Series(naa.index)\n",
    "ins_index = pd.Series(ins.index)\n",
    "cho_index = pd.Series(cho.index)\n",
    "CBF_index = pd.Series(CBF.index)\n",
    "aBV_index = pd.Series(aBV.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = ['_Glu+Gln_Conc_T2_overlaid_zeros.nii.gz', 'reg_', 'NAA+NAAG_Conc_T2_overlaid_zeros.nii.gz',\n",
    "               '_Ins_Conc_T2_overlaid_zeros.nii.gz', '_GPC+PCh_Conc_T2_overlaid_zeros.nii.gz',\n",
    "               '_brain.nii_normmi_flirt_CBF_05_masked.nii', '_T1_07', '_T1_05',\n",
    "               '_brain.nii_normmi_flirt_CBF_03_masked.nii',\n",
    "               '_brain.nii_normmi_flirt_CBF_07_masked.nii', '_']\n",
    "\n",
    "for string in string_list:\n",
    "    glu_index = glu_index.apply(lambda x: x.replace(string, ''))\n",
    "    naa_index = naa_index.apply(lambda x: x.replace(string, ''))\n",
    "    ins_index = ins_index.apply(lambda x: x.replace(string, ''))\n",
    "    cho_index = cho_index.apply(lambda x: x.replace(string, ''))\n",
    "    CBF_index = CBF_index.apply(lambda x: x.replace(string, ''))\n",
    "    aBV_index = aBV_index.apply(lambda x: x.replace(string, ''))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glu.set_index(glu_index, inplace=True)\n",
    "naa.set_index(naa_index, inplace=True)\n",
    "ins.set_index(ins_index, inplace=True)\n",
    "cho.set_index(cho_index, inplace=True)\n",
    "CBF.set_index(CBF_index, inplace=True)\n",
    "aBV.set_index(aBV_index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = group\n",
    "df_list = [fmri, CBF, aBV, FA, MD, glu, cho, ins, naa]\n",
    "\n",
    "for df in df_list:\n",
    "    data = pd.merge(data, df, on='ID', how='left')\n",
    "    \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping some features and samples containing high amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping NA\n",
    "data = data.dropna(axis = 1, thresh = round((0.5)*data.shape[0])) #removing features existing in less than half of the samples \n",
    "data = data.dropna(axis = 0, thresh = round((0.5)*data.shape[1])) #removing samples having features less than half of the total features \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the merged DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) \n",
    "pd.options.display.max_rows = 100\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the number of missing values in each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking missing values in features\n",
    "pd.options.display.max_rows = 1000\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the missing values by a constant that is not contained in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the number of paricipants in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Healthy Controls:', (data.group == 0).sum())\n",
    "print('Number of Cognitively Normal Parkinson Disease Patients:', (data.group == 1).sum())\n",
    "print('Number of Mild Cognitive Parkinson Disease Patient:', (data.group == 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the pearson correlations between each features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.heatmap(corr_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decomposing the modalities from the merged data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_reduced = data.loc[:, data.columns.str.contains('_fmri', regex=True)]\n",
    "aBV_reduced = data.loc[:, data.columns.str.contains('_aBV', regex=True)]\n",
    "FA_reduced = data.loc[:, data.columns.str.contains('_FA', regex=True)]\n",
    "MD_reduced = data.loc[:, data.columns.str.contains('_MD', regex=True)]\n",
    "CBF_reduced = data.loc[:, data.columns.str.contains('_CBF', regex=True)]\n",
    "spectroscopy_reduced = data.loc[:, data.columns.str.contains('_glu|_cho|_ins|_naa', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the explained variances of each modalities using Principal Component Analysis (PCA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca_components = 5\n",
    "\n",
    "print('Total explined variance with PCA of CBF features is {}'.format(PCA(n_components=n_pca_components).fit((CBF_reduced)).explained_variance_ratio_.sum()))\n",
    "print('Total explined variance with PCA of aBV features is {}'.format(PCA(n_components=n_pca_components).fit((aBV_reduced)).explained_variance_ratio_.sum()))\n",
    "print('Total explined variance with PCA of FA features is {}'.format(PCA(n_components=n_pca_components).fit((FA_reduced)).explained_variance_ratio_.sum()))\n",
    "print('Total explined variance with PCA of MD features is {}'.format(PCA(n_components=n_pca_components).fit((MD_reduced)).explained_variance_ratio_.sum()))\n",
    "print('Total explined variance with PCA of fmri features is {}'.format(PCA(n_components=n_pca_components).fit((fmri_reduced)).explained_variance_ratio_.sum()))\n",
    "print('Total explined variance with PCA of spectroscopy features is {}'.format(PCA(n_components=n_pca_components).fit((spectroscopy_reduced)).explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the number of features that will be selected as the most important in each cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change number of selected features\n",
    "number_of_selected_features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Recursive Feature Elimination (RFE) objects with RandomForestClassifier and ExtraTreesClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection Algorithms\n",
    "fs1 = RFE(RandomForestClassifier(n_estimators=100), n_features_to_select=number_of_selected_features, verbose=2)\n",
    "fs2 = RFE(ExtraTreesClassifier(n_estimators=100, bootstrap=True), n_features_to_select=number_of_selected_features, verbose=2)\n",
    "\n",
    "#Add more feature selection options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the functions that will select each modality in pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fmri = FunctionTransformer(lambda x: x[list(fmri_reduced.columns)], validate=False)\n",
    "get_aBV = FunctionTransformer(lambda x: x[list(aBV_reduced.columns)], validate=False)\n",
    "get_CBF = FunctionTransformer(lambda x: x[list(CBF_reduced.columns)], validate=False)\n",
    "get_FA = FunctionTransformer(lambda x: x[list(FA_reduced.columns)], validate=False) \n",
    "get_MD = FunctionTransformer(lambda x: x[list(MD_reduced.columns)], validate=False)\n",
    "get_spectroscopy = FunctionTransformer(lambda x: x[list(spectroscopy_reduced.columns)], validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining the preprocessing steps for each modality with FeatureUnion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('aBV_features', Pipeline([\n",
    "                    ('selector', get_aBV),\n",
    "                    ('pca', PCA(n_components=n_pca_components))\n",
    "                ])),\n",
    "                ('FA_features', Pipeline([\n",
    "                    ('selector', get_FA),\n",
    "                    ('pca', PCA(n_components=n_pca_components))\n",
    "                ])),\n",
    "                 ('MD_features', Pipeline([\n",
    "                    ('selector', get_MD),\n",
    "                    ('pca', PCA(n_components=n_pca_components))\n",
    "                ])),\n",
    "                ('spectroscopy_features', Pipeline([\n",
    "                    ('selector', get_spectroscopy),\n",
    "                    ('pca', PCA(n_components=n_pca_components))\n",
    "                ])),\n",
    "                ('fmri_features', Pipeline([\n",
    "                    ('selector', get_fmri)\n",
    "                ])),\n",
    "                ('CBF_features', Pipeline([\n",
    "                    ('selector', get_CBF)\n",
    "                ]))\n",
    "                \n",
    "             ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the pipelines for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipelines\n",
    "\n",
    "pipe1 = Pipeline([('union', join_features),\n",
    "                 ('fs', fs1)])\n",
    "\n",
    "pipe2 = Pipeline([('union', join_features),\n",
    "                 ('fs', fs2)])\n",
    "\n",
    "\n",
    "#Add more pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelist = [pipe1, pipe2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the time required for the features selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for pipe in pipelist:\n",
    "    pipe = pipe.fit((data.drop(labels=['group'], axis=1)), data['group'])\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_loops = 100\n",
    "Estimated_Time = ((end - start)*num_of_loops)\n",
    "print('Estimated Time:',Estimated_Time/60,'min','or',Estimated_Time/3600,'h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing feature selection num_of_loops times with different train-test splits in each loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('Program start to run at',time.localtime())\n",
    "counter_collections=collections.Counter()\n",
    "\n",
    "\n",
    "for pipe in pipelist:\n",
    "    selectedfeatures=[]\n",
    "\n",
    "    for i in range(num_of_loops):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data.drop(labels=['group'], axis=1), data['group'], test_size=0.2)\n",
    "\n",
    "\n",
    "        # run pipelines\n",
    "        pipe = pipe.fit(X_train, y_train)\n",
    "        selectedfeatures.append(tuple(pipe.steps[1][1].get_support(indices=True)))          #for RF-RFE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    counter=collections.Counter(selectedfeatures)\n",
    "    counter_collections = counter_collections + counter\n",
    "    \n",
    "    print('Most Common Selected Features:',np.array(counter.most_common))    #change according to number of selected features\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print('Total Selected Features in all methods:',np.array(counter_collections.most_common))\n",
    "\n",
    "end = time.time()\n",
    "print('Computation Time:',(end - start)/60,'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining names of the transformed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_col_list = []\n",
    "pca_modality_list = ['aBV', 'FA', 'MD', 'spectroscopy']\n",
    "for modality in pca_modality_list:\n",
    "    for i in range(1, n_pca_components+1, 1):\n",
    "        pca_col_list.append(modality + '_pca' + str(i))\n",
    "        \n",
    "for i in fmri_reduced.columns:\n",
    "    pca_col_list.append(i)\n",
    "    \n",
    "for i in CBF_reduced.columns:\n",
    "    pca_col_list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting the indices of the transformed features that are mostly selected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_index_list = [10, 21, 43, 76, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Selected features: ', [pca_col_list[index] for index in selected_feature_index_list]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the classifier for performing classification with selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing classification num_of_loops times and calculating mean accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "conf_matrix = 0\n",
    "\n",
    "for i in range(num_of_loops):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(labels=['group'], axis=1), data['group'], test_size=0.2, stratify=data['group'])\n",
    "    \n",
    "    X_train_transformed = join_features.fit_transform(X_train)\n",
    "    X_train_selected = X_train_transformed[:,selected_feature_index_list]    \n",
    "\n",
    "    X_test_transformed = join_features.transform(X_test)\n",
    "    X_test_selected = X_test_transformed[:,selected_feature_index_list]\n",
    "\n",
    "    clf.fit(X_train_selected, y_train)\n",
    "    accuracy += clf.score(X_test_selected, y_test)\n",
    "    conf_matrix += confusion_matrix(y_test, clf.predict(X_test_selected))\n",
    "\n",
    "mean_accuracy = accuracy / num_of_loops\n",
    "mean_conf_matrix = conf_matrix / num_of_loops\n",
    "\n",
    "print('Mean accuracy: ', mean_accuracy)\n",
    "print('Mean confusion matrix: ', mean_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
